{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0f66cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-SBe-Yh6W-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 문제 1: 카페 메뉴 도구 호출 체인 구현\n",
    "\n",
    "import re\n",
    "import os\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "from langchain_upstage import UpstageEmbeddings, ChatUpstage\n",
    "from langchain_community.tools import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce343c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n",
      "WA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9178d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 카페 메뉴 데이터 로드 및 벡터 DB 구축\n",
    "def create_cafe_vector_db():\n",
    "    # 카페 메뉴 텍스트 데이터를 로드\n",
    "    loader = TextLoader(\"../data/cafe_menu_data.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 메뉴 항목별로 분할\n",
    "    def split_menu_items(document):\n",
    "        pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "        menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "        \n",
    "        menu_documents = []\n",
    "        for i, item in enumerate(menu_items, 1):\n",
    "            # 메뉴 이름 추출\n",
    "            menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "            \n",
    "            menu_doc = Document(\n",
    "                page_content=item.strip(),\n",
    "                metadata={\n",
    "                    \"source\": document.metadata['source'],\n",
    "                    \"menu_number\": i,\n",
    "                    \"menu_name\": menu_name\n",
    "                }\n",
    "            )\n",
    "            menu_documents.append(menu_doc)\n",
    "        \n",
    "        return menu_documents\n",
    "    \n",
    "    # 메뉴 항목 분리 실행\n",
    "    menu_documents = []\n",
    "    for doc in documents:\n",
    "        menu_documents += split_menu_items(doc)\n",
    "    \n",
    "    # 임베딩 모델 설정\n",
    "    #embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "    \n",
    "    # FAISS 인덱스 생성\n",
    "    cafe_db = FAISS.from_documents(\n",
    "        documents=menu_documents, \n",
    "        embedding=embeddings_model\n",
    "    )\n",
    "    \n",
    "    # FAISS 인덱스 저장\n",
    "    cafe_db.save_local(\"../db/cafe_db\")\n",
    "    \n",
    "    return cafe_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "928297f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. 도구 정의\n",
    "# 웹 검색 도구\n",
    "@tool\n",
    "def tavily_search_func(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "    \n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "    ])\n",
    "    \n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\"\n",
    "print(type(tavily_search_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f7469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 위키피디아 검색 도구\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    \n",
    "    formatted_docs = [\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "    ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47bacc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar-pro\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LLM 모델 \n",
    "# llm = ChatOpenAI(\n",
    "#     #api_key=OPENAI_API_KEY,\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     temperature=0.7\n",
    "# )\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5,\n",
    ")\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45789a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm\n",
    ")\n",
    "\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")\n",
    "print(type(wiki_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1f99bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 카페 메뉴 검색 도구\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized cafe menu information from the encrypted database.\n",
    "    Use this tool only for cafe menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    #embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "    cafe_db = FAISS.load_local(\n",
    "        \"../db/cafe_db\", \n",
    "        embeddings_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    docs = cafe_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 카페 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "print(type(db_search_cafe_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ccfc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. 도구를 LLM에 바인딩\n",
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4a663d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. 간단한 도구 호출 체인 구현\n",
    "@chain\n",
    "def cafe_search_chain(user_input: str, config: RunnableConfig):\n",
    "    # 첫 번째 LLM 호출로 도구 사용 결정\n",
    "    ai_msg = llm_with_tools.invoke(user_input, config=config)\n",
    "    \n",
    "    # 도구 실행\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"db_search_cafe_func\":\n",
    "            tool_message = db_search_cafe_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "    \n",
    "    # 최종 답변 생성을 위한 프롬프트\n",
    "    final_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful cafe assistant. Provide accurate information based on the search results.\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"ai\", ai_msg.content if ai_msg.content else \"도구를 사용하여 정보를 검색했습니다.\"),\n",
    "        (\"human\", \"검색 결과: {tool_results}\")\n",
    "    ])\n",
    "    \n",
    "    # 도구 결과를 문자열로 변환\n",
    "    tool_results_str = \"\\n\\n\".join([str(msg.content) for msg in tool_msgs])\n",
    "    \n",
    "    # 최종 답변 생성\n",
    "    final_chain = final_prompt | llm\n",
    "    return final_chain.invoke({\n",
    "        \"user_input\": user_input,\n",
    "        \"tool_results\": tool_results_str\n",
    "    }, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff0be59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\n",
      "db_search_cafe_func: \n",
      "{'name': 'db_search_cafe_func', 'args': {'query': '아메리카노 가격 및 유래'}, 'id': 'chatcmpl-tool-5d358a1630fc4bb5a215d86bdcd416e7', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "wiki_summary: \n",
      "{'name': 'wiki_summary', 'args': {'query': '아메리카노 유래'}, 'id': 'chatcmpl-tool-7e69efbe6552492ebc18f145207874b5', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tavily_search_func: \n",
      "{'name': 'tavily_search_func', 'args': {'query': '2024년 서울 인기 카페 추천'}, 'id': 'chatcmpl-tool-abc86f0a044740e782fe6ae9e90eb49d', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "질문: 아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가요? 그리고 최근에 가장 인기 있는 서울에 있는 카페도 추천해 주세요.\n",
      "답변: ### 1. **아메리카노 가격**  \n",
      "- **핫 아메리카노**: 4,500원  \n",
      "- **아이스 아메리카노**: 4,500원  \n",
      "  (메뉴 데이터 기준, 카페마다 차이가 있을 수 있음)\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **아메리카노의 유래**  \n",
      "- **기원**: 20세기 초 이탈리아에서 유래.  \n",
      "  - \"아메리카노\"라는 이름은 미국 군인들이 유럽식 진한 에스프레소를 본국 스타일로 희석해 마신 데서 비롯됨.  \n",
      "  - 에스프레소에 뜨거운 물을 추가해 **블랙 커피** 형태로 만든 것이 특징.  \n",
      "- **특징**: 원두의 풍미를 가장 순수하게 즐길 수 있으며, 카페인 효과와 깔끔한 맛으로 전 세계적으로 사랑받음.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **2024년 서울 인기 카페 추천**  \n",
      "#### 📍 **성수동**  \n",
      "- **와아 (WA.A)**  \n",
      "  - **위치**: 서울특별시 성동구 상원2길 1-10 3층  \n",
      "  - **특징**: 와인 아이스크림으로 유명한 이색 카페. 디저트와 커피를 함께 즐기기 좋음.  \n",
      "  - **선정 이유**: \"취향 저격 간술 스팟\"으로 SNS에서 화제.\n",
      "\n",
      "#### 📍 **연희동**  \n",
      "- **헷키 (Hetki)**  \n",
      "  - **위치**: 서울특별시 서대문구 가재울로4길 62 1층  \n",
      "  - **특징**: 2024년 최고의 디저트 카페로 선정된 곳. 타르트와 커피 조합이 훌륭함.  \n",
      "  - **선정 이유**: \"한 입 먹으면 가격이 아깝지 않다\"는 후기가 많음.\n",
      "\n",
      "#### 📍 **삼각지**  \n",
      "- **취중서가**  \n",
      "  - **위치**: 서울특별시 용산구 한강대로 206-1 1층  \n",
      "  - **특징**: 칵테일과 커피를 함께 제공하는 감성 공간. 작업이나 사색하기 좋은 분위기.  \n",
      "  - **선정 이유**: \"조명과 분위기가 완벽한\" 카페로 추천.\n",
      "\n",
      "---\n",
      "\n",
      "### ✨ **추가 팁**  \n",
      "- **성수동 카페 거리**는 트렌디한 카페들이 밀집해 있어 다양한 선택지가 있음.  \n",
      "- **인스타그램**에서 `#서울카페추천` 해시태그로 최신 정보를 확인하는 것도 좋습니다!  \n",
      "\n",
      "카페 방문 전 영업시간과 메뉴는 공식 채널에서 다시 확인해 주세요. ☕\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. 실행 및 테스트\n",
    "if __name__ == \"__main__\":\n",
    "    # 벡터 DB 생성 (최초 1회만 실행)\n",
    "    try:\n",
    "        create_cafe_vector_db()\n",
    "        print(\"카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"벡터 DB 생성 중 오류: {e}\")\n",
    "    \n",
    "    # 질문에 답변    \n",
    "    query = \"아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가요? 그리고 최근에 가장 인기 있는 서울에 있는 카페도 추천해 주세요.\"\n",
    "    #query = \"최근에 가장 인기 있는 서울에 있는 카페를 추천해 주세요.\"\n",
    "    response = cafe_search_chain.invoke(query)\n",
    "    \n",
    "    print(\"질문:\", query)\n",
    "    print(\"답변:\", response.content)                                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
