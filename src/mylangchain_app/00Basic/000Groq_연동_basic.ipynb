{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_n\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "#load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: 당신은 개발자입니다.\n",
      "Human: 파이썬은 무엇인가요? 자세하게 설명해주세요\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002669E0B9970> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002669E0B9010> root_client=<openai.OpenAI object at 0x000002669DAD1010> root_async_client=<openai.AsyncOpenAI object at 0x000002669E0B8B60> model_name='moonshotai/kimi-k2-instruct-0905' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "응답: 파이썬(Python)은 1991년 네덜란드의 개발자 귀도 반 로섬(Guido van Rossum)이 발표된 **고급 프로그래밍 언어**입니다.  \n",
      "“고급”이라는 말은 **사람이 읽고 쓰기 쉽다**는 뜻이며, 파이썬의 핵심 철학은 “**코드를 읽는 것이 읽는 것처럼 쉽게**”(Readable Code)입니다.  \n",
      "아래에 파이썬을 둘러싼 **정의·특징·생태계·활용 분야·한계·시작 방법**까지 한눈에 정리해 드리겠습니다.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "1. 언어적 특성\n",
      "--------------------------------------------------------------------\n",
      "1-1. 인터프리터 언어(Interpreter)  \n",
      "소스코드(.py)를 바이트코드(.pyc)로 즉석 번역해 한 줄씩 실행합니다.  \n",
      "→ 개발-테스트 주기가 짧고, 대화형 프롬프트(REPL)로 실험 가능합니다.\n",
      "\n",
      "1-2. 동적 타이핑(Dynamic Typing)  \n",
      "변수에 값을 대입할 때 타입을 자동으로 결정합니다.  \n",
      "```python\n",
      "x = 3      # int\n",
      "x = \"Hi\"   # str (타입 변경 가능)\n",
      "```\n",
      "\n",
      "1-3. 강력한 표준 라이브러리 & “배터리 포함”(Batteries Included)  \n",
      "파일 I/O, 압축, 웹서버, JSON, CSV, 날짜-시간, 암호화 등 200개 이상의 표준 모듈이 기본 포함.\n",
      "\n",
      "1-4. 자동 메모리 관리 & GC  \n",
      "개발자가 malloc/free를 신경 쓸 필요 없음.\n",
      "\n",
      "1-5. 객체 지향 + 절차 지향 + 함수형 스타일 모두 지원  \n",
      "클래스, 상속, 데코레이터, 람다, 고차 함수(map, filter, reduce), 컴프리헨션 등.\n",
      "\n",
      "1-6. PEP 8 & “Zen of Python”  \n",
      "공식 스타일 가이드와 철학(‘아름다운 것이 낫다’, ‘명시적인 것이 암시적인 것보다 낫다’ 등)이 있어 **협업 시 코드 스타일이 통일되기 쉽습니다**.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "2. 생태계 / 패키지 관리\n",
      "--------------------------------------------------------------------\n",
      "2-1. PyPI(Python Package Index)  \n",
      "38만 개 이상의 서드파티 패키지가 등록돼 있어 `pip install` 한 방에 설치 가능.\n",
      "\n",
      "2-2. 가상 환경 도구  \n",
      "venv, virtualenv, conda, poetry, pipenv 등 → 의존성 충돌 방지.\n",
      "\n",
      "2-3. 버전 및 호환성  \n",
      "- 파이썬 2는 2020년 공식 지원 종료.  \n",
      "- 파이썬 3는 하위 호환성을 깨고 개선(3.6→3.7→3.8…).  \n",
      "- 각 OS(Win/Mac/Linux)에서 공식 인터프리터 제공.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "3. 주요 활용 분야\n",
      "--------------------------------------------------------------------\n",
      "3-1. 데이터 과학 / AI  \n",
      "NumPy, Pandas, SciPy, Matplotlib, Seaborn, Scikit-learn, TensorFlow, PyTorch, Hugging Face Transformers…  \n",
      "→ 파이썬은 이 분야의 “사실상 표준”(de-facto standard) 언어.\n",
      "\n",
      "3-2. 웹 개발  \n",
      "Django(풀스택·배터리 포함), Flask(마이크로), FastAPI(비동기·고성능), Streamlit(데이터 앱).  \n",
      "→ Instagram, Pinterest, Dropbox, Netflix 일부 서비스가 Django/FastAPI 기반.\n",
      "\n",
      "3-3. 자동화 / 스크립팅  \n",
      "파일 정리, 웹 스크래핑(BeautifulSoup, Selenium, Scrapy), 엑셀·PDF 조작(openpyxl, PyPDF2), OS 명령어 래핑.\n",
      "\n",
      "3-4. DevOps / 클라우드  \n",
      "Ansible(서버 자동화), Fabric(SSH 배포), AWS CDK, Pulumi, Serverless Framework, Azure SDK, GCP Client.\n",
      "\n",
      "3-5. 임베디드 / IoT  \n",
      "MicroPython, CircuitPython → 8-bit MCU(아두이노)에서도 파이썬 코드 실행.\n",
      "\n",
      "3-6. 게임 / 그래픽  \n",
      "Pygame, Panda3D, Ursina, Blender 스크립팅.\n",
      "\n",
      "3-7. 금융 / 트레이딩  \n",
      "Zipline, Backtrader, QuantConnect, PyAlgoTrade.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "4. 문법 예시\n",
      "--------------------------------------------------------------------\n",
      "```python\n",
      "# 1) 리스트 컴프리헨션\n",
      "squares = [x*x for x in range(10) if x % 2 == 0]\n",
      "\n",
      "# 2) with-as 문으로 안전한 파일 I/O\n",
      "with open('data.txt', encoding='utf-8') as f:\n",
      "    for line in f:\n",
      "        print(line.rstrip())\n",
      "\n",
      "# 3) 데코레이터\n",
      "import time, functools\n",
      "def timer(func):\n",
      "    @functools.wraps(func)\n",
      "    def wrapper(*a, **k):\n",
      "        t0 = time.perf_counter()\n",
      "        result = func(*a, **k)\n",
      "        print(f\"{func.__name__} took {time.perf_counter()-t0:.3f}s\")\n",
      "        return result\n",
      "    return wrapper\n",
      "\n",
      "@timer\n",
      "def heavy():\n",
      "    return sum(i*i for i in range(10_000_000))\n",
      "\n",
      "heavy()\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "5. 성능 & 한계\n",
      "--------------------------------------------------------------------\n",
      "- C/C++보다 10~100배 느릴 수 있음(루프 연산 기준).  \n",
      "- GIL(Global Interpreter Lock)로 인해 **CPU-bound 멀티스레딩**은 효과 ↓  \n",
      "  → 병렬 처리가 필요하면 multiprocessing, Cython, Numba, PyPy, Rust 확장 등 활용.  \n",
      "- 모바일 앱 네이티브 개발용으론 주류 아님(Kivy, BeeWare는 제한적).\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "6. 다른 언어와 비교 (한 줄 요약)\n",
      "--------------------------------------------------------------------\n",
      "- C/C++ : 속도↑ / 개발속도↓ / 메모리 수동 관리  \n",
      "- Java : 정적 타이핑 / JVM 생태계 / 장치 독립적  \n",
      "- JavaScript : 브라우저·Node 전용 / 이벤트 기반  \n",
      "- Go : 간결·고병행 / 풍부한 표준库 / 덜 유연한 제네릭  \n",
      "- Rust : 메모리 안전·최고 속도 / 학습 곡선 가파름  \n",
      "- R : 통계 전문 / 범용성↓ / 속도↓  \n",
      "- 파이썬 : 범용·배우기 쉬움·생태계 최강 / 속도↓(보완 수단 존재)\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "7. 시작하기 (Windows 기준)\n",
      "--------------------------------------------------------------------\n",
      "1) 공식 사이트 python.org 에서 3.12 64-bit 설치  \n",
      "2) 설치 시 “Add Python to PATH” 체크  \n",
      "3) 터미널(명령 프롬프트) 실행  \n",
      "```bash\n",
      "python -m pip install --upgrade pip\n",
      "python -m venv .venv\n",
      ".\\.venv\\Scripts\\activate\n",
      "pip install ipython jupyter pandas scikit-learn\n",
      "```\n",
      "4) VS Code 확장 “Python”, “Jupyter” 설치  \n",
      "5) `code .` → `hello.py` 작성 → F5 실행\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "8. 학습 로드맵(추천)\n",
      "--------------------------------------------------------------------\n",
      "1. 기초 문법(변수, 자료형, 제어문, 함수, 클래스)  \n",
      "2. 표준 라이브러리(os, pathlib, datetime, collections, itertools)  \n",
      "3. 가상환경 & 패키징(venv, setuptools, wheel)  \n",
      "4. 단위 테스트(pytest) + 문서화(Sphinx)  \n",
      "5. 데이터 처리(NumPy, Pandas)  \n",
      "6. 웹 or AI 선택  \n",
      "   - 웹 : Django 튜토리얼 → REST API → 배포(Docker + Gunicorn + Nginx)  \n",
      "   - AI : Matplotlib → Scikit-learn 머신러닝 → 딥러닝(PyTorch)  \n",
      "7. 성능 최적화(Cython, Numba, multiprocessing, asyncio)  \n",
      "8. 오픈소스 기여 & 코드 리뷰\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "9. 마무리\n",
      "--------------------------------------------------------------------\n",
      "파이썬은 **“생산성이 높고, 생태계가 넓으며, 진입 장벽이 낮은”** 언어입니다.  \n",
      "단순 스크립트부터 수백만 명이 사용하는 대규모 서비스까지 모두 가능하며,  \n",
      "“몇 줄만으로 프로토타입을 만들어 보여주는” 능력은 파이썬의 가장 큰 무기입니다.  \n",
      "성능이 중요한 부분은 C/C++/Rust 확장이나 vectorization으로 보완하면 되므로,  \n",
      "현대 소프트웨어 개발에서 **‘두뇌’ 역할을 담당하는 고속 프로토타이핑 언어**로 자리 잡았습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D80BFAB4D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D80BFBD8E0>, root_client=<openai.OpenAI object at 0x000001D80BA955B0>, root_async_client=<openai.AsyncOpenAI object at 0x000001D80BFAB530>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"지구의 자전주기는 얼마인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "지구의 자전주기는 24시간입니다. 이를 하루라고 부릅니다.\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
